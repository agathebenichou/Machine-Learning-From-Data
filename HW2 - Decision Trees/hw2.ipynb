{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLGpUAA3cs_C",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6bd0516e7cb654f5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "# Exercise 2: Decision Trees\n",
        "\n",
        "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
        "\n",
        "## In this exercise you will perform the following:\n",
        "1. Practice OOP in python.\n",
        "2. Implement two impurity measures: Gini and Entropy.\n",
        "3. Construct a decision tree algorithm.\n",
        "4. Prune the tree to achieve better results.\n",
        "5. Visualize your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpT8Ax8Rcs_H",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ed9fe7b1026e33cb",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make matplotlib figures appear inline in the notebook\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1tmBsIlcs_J",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c6ac605270c2b091",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Warmup - OOP in python\n",
        "\n",
        "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in Java.\n",
        "\n",
        "\n",
        "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-7uF_xCcs_J"
      },
      "outputs": [],
      "source": [
        "class Node(object):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.children = []\n",
        "\n",
        "    def add_child(self, node):\n",
        "        self.children.append(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOQH0DTtcs_K",
        "outputId": "d0ede2b9-fc57-4c8c-8bc6-40f622625e3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<__main__.Node at 0x7f75edbab750>, <__main__.Node at 0x7f75edbab7d0>]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = Node(5)\n",
        "p = Node(6)\n",
        "q = Node(7)\n",
        "n.add_child(p)\n",
        "n.add_child(q)\n",
        "n.children"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JBLZQrscs_L",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2f1ceb251c649b62",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
        "\n",
        "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
        "one (=there are only two classes **edible** and **poisonous**). \n",
        "    \n",
        "The dataset contains 8124 observations with 22 features:\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "4. bruises: bruises=t,no=f\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\n",
        "8. gill-size: broad=b,narrow=n\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "10. stalk-shape: enlarging=e,tapering=t\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "16. veil-type: partial=p,universal=u\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
        "18. ring-number: none=n,one=o,two=t\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
        "21. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
        "\n",
        "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5E6CQtpcs_M",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d79cb4542926ad3f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('agaricus-lepiota.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqRdx8acs_M"
      },
      "source": [
        "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP3cqFDYcs_N"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "# TODO: Find columns with missing values and remove them from the data.#\n",
        "#############################################################################\n",
        "# drop columns if there are missing values \n",
        "data.dropna(axis=1, inplace=True)\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Io_gE4Zcs_N"
      },
      "source": [
        "We will split the dataset to `Training` and `Testing` datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKC9PyhVcs_N",
        "outputId": "28bf594c-3b87-42ac-c14e-20d273fc3230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape:  (6093, 22)\n",
            "Testing dataset shape:  (2031, 22)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Making sure the last column will hold the labels\n",
        "X, y = data.drop('class', axis=1), data['class']\n",
        "X = np.column_stack([X,y])\n",
        "# split dataset using random_state to get the same split each time\n",
        "X_train, X_test = train_test_split(X, random_state=99)\n",
        "\n",
        "print(\"Training dataset shape: \", X_train.shape)\n",
        "print(\"Testing dataset shape: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_uHqKjUcs_O",
        "outputId": "76ca1cf1-f273-4a20-9011-9a097c14ef88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8124,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inkeNWn2cs_O",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fd7b0191f3f1e897",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Impurity Measures\n",
        "\n",
        "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy`. You are encouraged to test your implementation (10 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giCFzIfGcs_O"
      },
      "outputs": [],
      "source": [
        "def calc_gini(data):\n",
        "    \"\"\"\n",
        "    Calculate gini impurity measure of a dataset.\n",
        " \n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        " \n",
        "    Returns the gini impurity.    \n",
        "    \"\"\"\n",
        "    gini = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    \n",
        "    labels = np.unique(data[:,-1], return_counts=True)[1]\n",
        "    p = (labels/data.shape[0])\n",
        "    gini = 1-(p**2).sum()\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return gini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QpMO1IWcs_O"
      },
      "outputs": [],
      "source": [
        "def calc_entropy(data):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a dataset.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "\n",
        "    Returns the entropy of the dataset.    \n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    labels = np.unique(data[:,-1], return_counts=True)[1]\n",
        "    p = labels/data.shape[0]\n",
        "    entropy = -np.dot(p,np.log2(p))\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOPwsqics_P",
        "outputId": "5fb2f18b-947f-46fa-a317-20ef9e91ac9c",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4995636322379775, 0.9993703627906085)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##### Your Tests Here #####\n",
        "calc_gini(X), calc_entropy(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0AdTsz7cs_P"
      },
      "source": [
        "## Goodness of Split\n",
        "\n",
        "Given a feature the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
        "$$\n",
        "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
        "$$\n",
        "\n",
        "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
        "$$\n",
        "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
        "$$\n",
        "Where:\n",
        "$$\n",
        "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
        "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
        "$$\n",
        "NOTE: you can add more parameters to the function and you can also add more returning variables (The given parameters and the given returning variable should not be touch). (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP2Odk9Xcs_R"
      },
      "outputs": [],
      "source": [
        "def goodness_of_split(data, feature, impurity_func, gain_ratio=False):\n",
        "    \"\"\"\n",
        "    Calculate the goodness of split of a dataset given a feature and impurity function.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "    - feature: the feature index.\n",
        "    - impurity func: a function that calculates the impurity.\n",
        "    - gain_ratio: goodness of split or gain ratio flag.\n",
        "\n",
        "    Returns the goodness of split (or the Gain Ration).  \n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    #gain ratio is relevant only for entropy\n",
        "    if gain_ratio is True:\n",
        "        assert impurity_func == calc_entropy\n",
        "\n",
        "    # extractvalues for that feature from data with labels\n",
        "    feature_values = data[:,[feature, -1]]\n",
        "\n",
        "    # for each feature value, group with labels\n",
        "    grouped_feature_values = feature_values[np.argsort(feature_values[:,0])]\n",
        "\n",
        "    # split labels and values for the feature into distinct arrays\n",
        "    split_features_labels = np.split(grouped_feature_values[:,1], np.unique(grouped_feature_values[:,0], return_index = True)[1])[1:]\n",
        "\n",
        "    # array of impurities for each group\n",
        "    impurities = np.array([impurity_func(grou[:,None]) for grou in split_features_labels])\n",
        "\n",
        "    # weighted averages\n",
        "    probs = (np.unique(grouped_feature_values[:,0], return_counts=True)[1] / grouped_feature_values[:,0].shape[0])\n",
        "\n",
        "    # goodness of split calculation\n",
        "    goodness = (impurity_func(data) - np.dot(probs,impurities))\n",
        "\n",
        "    if gain_ratio is True and goodness > 0.000001:\n",
        "      goodness /= calc_entropy(feature_values[:,0][:,None])\n",
        "      \n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return goodness    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm3Ay6kNcs_T",
        "outputId": "ea1e19ad-5ea7-4b05-d694-746ba8ce279f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.49516949727436654\n",
            "0.011999711708812375\n"
          ]
        }
      ],
      "source": [
        "print(goodness_of_split(X, 4, calc_entropy, gain_ratio=False))\n",
        "print(goodness_of_split(X, 1, calc_entropy, gain_ratio=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc0Mn9e1cs_T"
      },
      "source": [
        "## Building a Decision Tree\n",
        "\n",
        "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
        "\n",
        "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes and you are free to use them as you see fit. We recommend that every node will hold the feature and value used for the split and its children.\n",
        "2. Your code should support both Gini and Entropy as impurity measures. \n",
        "3. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
        "\n",
        "Complete the class `DecisionNode`. The structure of this class is entirely up to you. \n",
        "\n",
        "Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class. (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OafACzpcs_T"
      },
      "outputs": [],
      "source": [
        "class DecisionNode:\n",
        "    \"\"\"\n",
        "    This class will hold everything you require to construct a decision tree.\n",
        "    The structure of this class is up to you. However, you need to support basic \n",
        "    functionality as described above. It is highly recommended that you \n",
        "    first read and understand the entire exercise before diving into this class.\n",
        "    \"\"\"\n",
        "    def __init__(self, depth, data, feature, feature_value, prediction, impurity):\n",
        "        self.feature = feature # column index of feature being tested\n",
        "        self.feature_value = feature_value # value of feature selected from parent\n",
        "        self.children = [] # children of a node\n",
        "        self.data = data # data the node holds\n",
        "        self.prediction = prediction\n",
        "        self.impurity = impurity\n",
        "        self.depth = depth # distance from root node\n",
        "\n",
        "    def add_child(self, node):\n",
        "        self.children.append(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuajFo0fcs_T"
      },
      "outputs": [],
      "source": [
        "import queue\n",
        "\n",
        "def build_tree(data, impurity, gain_ratio=False, min_samples_split=1, max_depth=1000):\n",
        "    \"\"\"\n",
        "    Build a tree using the given impurity measure and training dataset. \n",
        "    You are required to fully grow the tree until all leaves are pure. \n",
        "\n",
        "    Input:\n",
        "    - data: the training dataset.\n",
        "    - impurity: the chosen impurity measure. Notice that you can send a function\n",
        "                as an argument in python.\n",
        "    - gain_ratio: goodness of split or gain ratio flag\n",
        "    - min_samples_split: the minimum number of samples required to split an internal node\n",
        "    - max_depth: the allowable depth of the tree\n",
        "\n",
        "    Output: the root node of the tree.\n",
        "    \"\"\"\n",
        "    root = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    q = queue.Queue()\n",
        "    depth = 0\n",
        "\n",
        "    # create the root node with all the samples\n",
        "    root = DecisionNode(depth=depth, \n",
        "                        data=pd.DataFrame(data), \n",
        "                        feature=None, \n",
        "                        feature_value='root',\n",
        "                        prediction=None, \n",
        "                        impurity=None)\n",
        "\n",
        "    # insert the node to initilalize a queue\n",
        "    q.put(root)\n",
        "\n",
        "    # while there are incomplete nodes on the queue\n",
        "    while q.qsize() > 0:\n",
        "\n",
        "      # take node from the queue\n",
        "      node = q.get()\n",
        "\n",
        "      #set prediction on a node by majority\n",
        "      data_y_labels, data_y_counter = np.unique(node.data.to_numpy()[:,-1], return_counts=True)\n",
        "      node.prediction = data_y_labels[np.argmax(data_y_counter)]\n",
        "\n",
        "      # if height is greater, stop building tree\n",
        "      if node.depth >= max_depth: \n",
        "        continue\n",
        "\n",
        "      # check if impurity is close to  0 (perfectly classified)\n",
        "      node.impurity = impurity(node.data.to_numpy())\n",
        "      \n",
        "      # if np.isclose(node.impurity,0): \n",
        "      #  continue\n",
        "      #mark it as complete (make it a leaf)\n",
        "      if node.impurity == 0: \n",
        "        continue\n",
        "\n",
        "      # if not pure/perfectly classified, find best decision attribute for the node\n",
        "      attributes_gos = []\n",
        "      \n",
        "      # for every feature in the node (not the labels), calculate goodness of split\n",
        "      for feature in range(node.data.columns.size-1):\n",
        "        attributes_gos.append(goodness_of_split(node.data.to_numpy(), feature, impurity, gain_ratio))\n",
        "      \n",
        "      # if np.isclose(np.max(attributes_gos),0):\n",
        "      #   continue\n",
        "      # if max GOS is 0, then it does not differ from its parent so its a leaf\n",
        "      if np.max(attributes_gos) == 0:\n",
        "        continue\n",
        "\n",
        "      # set that best attribute to the node (setting the index)\n",
        "      node.feature = node.data.columns[np.argmax(attributes_gos)]\n",
        "\n",
        "      #don't split a node if the number of samples in it is less or equal to the min_samples_split value\n",
        "      if len(node.data.index) <= min_samples_split:\n",
        "        continue\n",
        "      \n",
        "      # for each value in that attribute, create a new child for the node\n",
        "      for val in np.unique(node.data[node.feature]):\n",
        "\n",
        "        # get subset of data filtered for that value\n",
        "        value_data = node.data[node.data[node.feature] == val]\n",
        "        value_data = value_data.drop([node.feature], axis = 1)\n",
        "\n",
        "        # distribute training examples to child for that value\n",
        "        child = DecisionNode(depth=node.depth+1, \n",
        "                             data=value_data, \n",
        "                             feature=None, \n",
        "                             feature_value=val,\n",
        "                             prediction=None,\n",
        "                             impurity=None)\n",
        "\n",
        "        # add child to node\n",
        "        node.add_child(child)\n",
        "\n",
        "        # insert all non empty children to queue\n",
        "        q.put(child) \n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID7m1d0Scs_U"
      },
      "outputs": [],
      "source": [
        "# python supports passing a function as an argument to another function.\n",
        "tree_gini = build_tree(data=X_train, impurity=calc_gini) # gini and goodness of split\n",
        "tree_entropy = build_tree(data=X_train, impurity=calc_entropy) # entropy and goodness of split\n",
        "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True) # entropy and gain ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FBg0stcs_U"
      },
      "source": [
        "## Tree evaluation\n",
        "\n",
        "Complete the functions `predict` and `calc_accuracy`. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0HMyRczcs_U"
      },
      "outputs": [],
      "source": [
        "def predict(node, instance):\n",
        "    \"\"\"\n",
        "    Predict a given instance using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - root: the root of the decision tree.\n",
        "    - instance: an row vector from the dataset. Note that the last element \n",
        "                of this vector is the label of the instance.\n",
        " \n",
        "    Output: the prediction of the instance.\n",
        "    \"\"\"\n",
        "    pred = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    \n",
        "    current_node = node\n",
        "    stop = False\n",
        "\n",
        "    # while current node has children\n",
        "    while len(current_node.children)> 0 and stop == False:\n",
        "\n",
        "      # get the feature for which node splits\n",
        "      current_split_feature = current_node.feature\n",
        "\n",
        "      #get all the feature value of children\n",
        "      child_features = [child.feature_value for child in current_node.children]\n",
        "\n",
        "      # for each of the children\n",
        "      for child in current_node.children: \n",
        "\n",
        "        # extract feature value for that child\n",
        "        child_feature_value = child.feature_value\n",
        "\n",
        "        # if instance val not in child feature vals, flag stop\n",
        "        if instance[current_split_feature] not in child_features:\n",
        "          stop = True\n",
        "\n",
        "        # if child value is equal to the feature for which instance splits\n",
        "        if instance[current_split_feature] == child_feature_value: \n",
        "          current_node = child\n",
        "          break\n",
        "\n",
        "    node = current_node\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return node.prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cydKDSRvcs_U"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(node, dataset):\n",
        "    \"\"\"\n",
        "    Predict a given dataset using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        "    - dataset: the dataset on which the accuracy is evaluated\n",
        " \n",
        "    Output: the accuracy of the decision tree on the given dataset (%).\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    correct_predictions = 0\n",
        "    # for each instance\n",
        "    for instance_row in dataset:\n",
        "\n",
        "      # get instance prediction\n",
        "      prediction = predict(node, instance_row)\n",
        "\n",
        "      # get label for that dataset\n",
        "      label = instance_row[-1]\n",
        "\n",
        "      if prediction == label:\n",
        "        correct_predictions += 1\n",
        "      \n",
        "    accuracy = correct_predictions / len(dataset)\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LL8Pp7hcs_V"
      },
      "source": [
        "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nndi8Khucs_V",
        "outputId": "8df89888-633a-459e-e80c-410a4e1105ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train for Gini: 99.24503528639423%\n",
            "X_test for Gini: 77.49876907927128%\n",
            "X_train for Entropy: 99.40915805022156%\n",
            "X_test for Entropy: 77.25258493353027%\n",
            "X_train for Split Gain Ratio: 99.63892991957984%\n",
            "X_test for Split Gain Ratio: 78.53274249138356%\n",
            "The tree that resulted in the best test accuracy was: Split Gain Ratio with 78.53274249138356%\n"
          ]
        }
      ],
      "source": [
        "#### Your code here ####\n",
        "\n",
        "gini_train_accuracy = calc_accuracy(tree_gini, X_train)\n",
        "gini_test_accuracy = calc_accuracy(tree_gini, X_test)\n",
        "\n",
        "print(f\"X_train for Gini: {gini_train_accuracy * 100}%\")\n",
        "print(f\"X_test for Gini: {gini_test_accuracy * 100}%\")\n",
        "\n",
        "entropy_train_accuracy = calc_accuracy(tree_entropy, X_train)\n",
        "entropy_test_accuracy = calc_accuracy(tree_entropy, X_test)\n",
        "\n",
        "print(f\"X_train for Entropy: {entropy_train_accuracy * 100}%\")\n",
        "print(f\"X_test for Entropy: {entropy_test_accuracy * 100}%\")\n",
        "\n",
        "split_train_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_train)\n",
        "split_test_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_test)\n",
        "\n",
        "print(f\"X_train for Split Gain Ratio: {split_train_accuracy * 100}%\")\n",
        "print(f\"X_test for Split Gain Ratio: {split_test_accuracy * 100}%\")\n",
        "\n",
        "options = ['Gini', 'Entropy', 'Split Gain Ratio']\n",
        "best_accuracy = np.max([gini_test_accuracy, entropy_test_accuracy, split_test_accuracy])\n",
        "best_accuracy_tree = options[np.argmax([gini_test_accuracy, entropy_test_accuracy, split_test_accuracy])]\n",
        "\n",
        "print(f\"The tree that resulted in the best test accuracy was: {best_accuracy_tree} with {best_accuracy*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQiBCnEWcs_V"
      },
      "source": [
        "## Depth pruning\n",
        "\n",
        "(15 points)\n",
        "\n",
        "Consider the following max_depth values: [1, 2, 3, 4, 5, 6, 7, 8]. For each value, construct a tree and prune it according to the max_depth value = don't let the tree to grow beyond this depth. Next, calculate the training and testing accuracy.<br>\n",
        "On a single plot, draw the training and testing accuracy as a function of the max_depth. Mark the best result on the graph with red circle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCtA8BArcs_V"
      },
      "outputs": [],
      "source": [
        "#### Your code here ####\n",
        "max_depth_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "train_accuracies_list = []\n",
        "test_accuracies_list = []\n",
        "\n",
        "for value in max_depth_list:\n",
        "  tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth=value)\n",
        "  depth_train_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_train)\n",
        "  depth_test_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_test)\n",
        "  train_accuracies_list.append(depth_train_accuracy)\n",
        "  test_accuracies_list.append(depth_test_accuracy)\n",
        "  # print (\"*\")\n",
        "  # print(value)\n",
        "  # print(depth_test_accuracy)\n",
        "  # print(count_nodes(tree_entropy_gain_ratio))\n",
        "  # print(\"*\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zG9P67CIosU_",
        "outputId": "df3125c3-d9c9-4749-9423-4062629cc14b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#from matplotlib import style\n",
        "#style.use('dark_background')\n",
        "plt.plot(max_depth_list,train_accuracies_list, label=\"Train Accuracies\")\n",
        "plt.plot(max_depth_list,test_accuracies_list, label=\"Test Accuracies\")\n",
        "plt.xlabel(\"Depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "best_x_point = max_depth_list[np.argmax(test_accuracies_list)]\n",
        "best_y_point = np.max(test_accuracies_list)\n",
        "_ = plt.scatter([best_x_point],[best_y_point], facecolors='none', edgecolors='r' ,s=100)\n",
        "_ = plt.xticks(max_depth_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN5qDYR7cs_V"
      },
      "source": [
        "## Min Samples Split\n",
        "\n",
        "(15 points)\n",
        "\n",
        "Consider the following min_samples_split values: [1, 5, 10, 20, 50]. For each value, construct a tree and prune it according to the min_samples_split value = don't split a node if the number of sample in it is less or equal to the min_samples_split value. Next, calculate the training and testing accuracy.<br>\n",
        "On a single plot, draw the training and testing accuracy as a function of the min_samples_split. Mark the best result on the graph with red circle. (make sure that the x-axis ticks represent the values of min_samples_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsUvBcLEcs_V"
      },
      "outputs": [],
      "source": [
        "#### Your code here ####\n",
        "min_samples_split = [1, 5, 10, 20, 50]\n",
        "train_accuracies_list = []\n",
        "test_accuracies_list = []\n",
        "\n",
        "for value in min_samples_split:\n",
        "  tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split=value)\n",
        "  split_train_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_train)\n",
        "  split_test_accuracy = calc_accuracy(tree_entropy_gain_ratio, X_test)\n",
        "  train_accuracies_list.append(split_train_accuracy)\n",
        "  test_accuracies_list.append(split_test_accuracy)\n",
        "  # print (\"*\")\n",
        "  # print(value)\n",
        "  # print(split_test_accuracy)\n",
        "  # print(count_nodes(tree_entropy_gain_ratio))\n",
        "  # print(\"*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "cWrBDixfosVA",
        "outputId": "a05dbbd0-4e27-4b2c-fc5e-e84a4eba0c64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bn+8e+TgUTmKUACQrDiACRhiIKICiKIijjggIqV2qO1p+pprdaxDrSe2lN/x6G1crQi0lJUVATFAWWoVhBIUGYH0CgJUwCZpwzv74+1EzbJTthJ9s7KcH+uK1fWXuOzQlh31vS+5pxDRESkrBi/CxARkbpJASEiIiEpIEREJCQFhIiIhKSAEBGRkOL8LiBS2rdv71JTU/0uQ0SkXsnOzt7mnEsKNa3BBERqaipZWVl+lyEiUq+Y2XcVTdMlJhERCUkBISIiIUUtIMxskpltNbNVFUw3M3vazNaZ2Qoz6xc07QYz+zrwdUO0ahQRkYpF8x7EZOAvwJQKpl8A9Ah8DQCeBQaYWVvgISATcEC2mc1yzv0QxVpFpIyCggJyc3M5ePCg36VIBCQmJtKlSxfi4+PDXiZqAeGc+8jMUiuZ5RJgivMag/rUzFqbWTIwBPjAObcDwMw+AEYC06JVq4iUl5ubS4sWLUhNTcXM/C5HasA5x/bt28nNzaV79+5hL+fnPYjOwIagz7mBcRWNL8fMbjazLDPLys/Pj1qhIo3RwYMHadeuncKhATAz2rVrV+WzwXp9k9o595xzLtM5l5mUFPIxXhGpAYVDw1Gdf0s/AyIPOD7oc5fAuIrGR8XO/Yd58sOvWLtpd7Q2ISJSL/kZELOAHweeZhoI7HLObQLeB0aYWRszawOMCIyLCsN4Zv463liWG61NiEg1bN++nT59+tCnTx86depE586dSz8fPny40mWzsrK4/fbbq7zNzz//HDPjvffeq27ZUTNo0KBa32bUblKb2TS8G87tzSwX78mkeADn3ETgHeBCYB2wH/hJYNoOM/sdsDSwqgklN6yjoVXTeM7ukcTsFZu494JTiYnRKbVIXdCuXTs+//xzAB5++GGaN2/OnXfeWTq9sLCQuLjQh7DMzEwyMzOrvM1p06YxePBgpk2bxsiRI6tXeBiKioqIjY2t0jILFy6MUjUVi9oZhHPuGudcsnMu3jnXxTn3gnNuYiAccJ5fOOd+5JxLc85lBS07yTl3YuDrxWjVWGJURjIbdx3ksw16klakLhs/fjy33HILAwYM4De/+Q1LlizhjDPOoG/fvgwaNIgvv/wSgAULFjBq1CjAC5cbb7yRIUOGcMIJJ/D000+HXLdzjunTpzN58mQ++OCDo27o/vGPfyQtLY2MjAzuueceANatW8d5551HRkYG/fr1Y/369UdtF+DWW29l8uTJgNcc0N13302/fv2YPn06zz//PKeddhoZGRmMGTOG/fv3A7BlyxYuu+wyMjIyyMjIKA2G5s2bl673T3/6E6eddhrp6ek89NBDAOzbt4+LLrqIjIwMevfuzSuvvFLjn3eDaYupJs47tSNN4mJ4a/km+ndr63c5InXOI2+tZs3GyN6n65nSkocu7lXl5XJzc1m4cCGxsbHs3r2bjz/+mLi4OD788EPuu+8+Xn/99XLLfPHFF8yfP589e/Zw8skn8/Of/7zc+wALFy6ke/fu/OhHP2LIkCHMnj2bMWPG8O677zJz5kwWL15M06ZN2bHDu6Bx3XXXcc8993DZZZdx8OBBiouL2bBhQ7ltB2vXrh3Lli0DvEtoN910EwAPPPAAL7zwArfddhu3334755xzDjNmzKCoqIi9e/cetY45c+bw9ddfs2TJEpxzjB49mo8++oj8/HxSUlKYPXs2ALt27aryz7asev0UU6S0SIxn6MlJvLNyE0XF6qNbpC678sorSy/P7Nq1iyuvvJLevXvzq1/9itWrV4dc5qKLLiIhIYH27dvToUMHtmzZUm6eadOmMXbsWADGjh3LtGneq1cffvghP/nJT2jatCkAbdu2Zc+ePeTl5XHZZZcB3ktoJdMrc/XVV5cOr1q1irPOOou0tDSmTp1aWvu8efP4+c9/DkBsbCytWrU6ah1z5sxhzpw59O3bl379+vHFF1/w9ddfk5aWxgcffMDdd9/Nxx9/XG656tAZRMCo9BTeX72FpTk7GHhCO7/LEalTqvOXfrQ0a9asdPi3v/0tQ4cOZcaMGeTk5DBkyJCQyyQkJJQOx8bGUlhYeNT0oqIiXn/9dWbOnMmjjz5a+mLZnj17qlRbXFwcxcXFpZ/LvncQXPv48eN58803ycjIYPLkySxYsCCsbTjnuPfee/nZz35WbtqyZct45513eOCBBxg2bBgPPvhgleovS2cQAcNO7cBx8bG8vWKj36WISJh27dpF587ee7Ql1/qrY+7cuaSnp7NhwwZycnL47rvvGDNmDDNmzGD48OG8+OKLpfcIduzYQYsWLejSpQtvvvkmAIcOHWL//v1069aNNWvWcOjQIXbu3MncuXMr3OaePXtITk6moKCAqVOnlo4fNmwYzz77LOAFV9lLReeffz6TJk0qvfSUl5fH1q1b2bhxI02bNmXcuHHcddddpZeyakIBEdC0SRznntqB91ZtprCo+NgLiIjvfvOb33DvvffSt2/fcmcFVTFt2rTSy0UlxowZU/o00+jRo8nMzKRPnz48/vjjAPz973/n6aefJj09nUGDBrF582aOP/54rrrqKnr37s1VV11F3759K9zm7373OwYMGMCZZ57JKaecUjr+qaeeYv78+aSlpdG/f3/WrFlz1HIjRozg2muv5YwzziAtLY0rrriCPXv2sHLlSk4//XT69OnDI488wgMPPFDtn0cJ85pCqv8yMzNdTTsMem/VJm75xzKm/scAzjyxfYQqE6mf1q5dy6mnnup3GRJBof5NzSzbORfymWCdQQQZcnIHmjXRZSYREVBAHCUxPpbzenbk3VWbKdBlJhFp5BQQZYxKT2Hn/gI+WbfN71JERHylgCjj7JPa0yIxjrdXbPK7FBERXykgykiIi2VEz068v3ozhwqL/C5HRMQ3CogQRmUks+dgIR9/pctMItJ4KSBCGHxie1o3jdfTTCI+qklz3+A12HesFlAvvfRSBg4cGKmSI2bixIlMmTLF7zLU1EYo8bExjOzVibeWb+RgQRGJ8VVrlldEau5YzX0fy4IFC2jevHmF/Sjs3LmT7OxsmjdvzjfffMMJJ5wQkbrLqqxZ8orccsstUamlqnQGUYFR6SnsO1zEgi+3+l2KiARkZ2dzzjnn0L9/f84//3w2bfIeJnn66afp2bMn6enpjB07lpycHCZOnMgTTzxBnz59+Pjjj8ut64033uDiiy9m7NixvPzyy6XjQzXjDaGb/B4yZAglL+hu27aN1NRUwGv2Y/To0Zx77rkMGzaMvXv3MmzYMPr160daWhozZ84s3d6UKVNIT08nIyOD66+/HvACseSN7fXr1zNy5Ej69+/PWWedxRdffAHA9OnT6d27NxkZGZx99tmR/DGX0hlEBQae0JZ2zZrw1opNjOyd7Hc5Iv569x7YvDKy6+yUBhc8Fvbszjluu+02Zs6cSVJSEq+88gr3338/kyZN4rHHHuPbb78lISGBnTt30rp1a2655ZZKzzqmTZvGgw8+SMeOHRkzZgz33XcfELoZ74qa/K7MsmXLWLFiBW3btqWwsJAZM2bQsmVLtm3bxsCBAxk9ejRr1qzh97//PQsXLqR9+/Yh13vzzTczceJEevToweLFi/nP//xP5s2bx4QJE3j//ffp3LkzO3fuDPvnWBUKiArExcZwQVonXs/OY//hQpo20Y9KxE+HDh1i1apVDB8+HPAasktO9v54S09P57rrruPSSy/l0ksvPea6tmzZwtdff83gwYMxM+Lj41m1ahXdunUr14w3hG7y+1iGDx9eOp9zjvvuu4+PPvqImJgY8vLy2LJlC/PmzePKK6+kffv2Ide7d+9eFi5cyJVXXnnUzwHgzDPPZPz48Vx11VVcfvnlx6ynOnTUq8So9BT+8en3zF27lYszUvwuR8Q/VfhLP1qcc/Tq1YtFixaVmzZ79mw++ugj3nrrLR599FFWrqz8bOfVV1/lhx9+oHv37gDs3r2badOmlV46Cldw896VNe09depU8vPzyc7OJj4+ntTU1HLzh1JcXEzr1q1L78UEmzhxIosXL2b27Nn079+f7Oxs2rWLbFcFugdRidNS29KhRYKeZhKpAxISEsjPzy8NiIKCAlavXl3ak9vQoUP54x//yK5du9i7dy8tWrSosD+HadOm8d5775GTk0NOTg7Z2dm8/PLLFTbjHarJb/C6Ec3Ozgbgtddeq7D2Xbt20aFDB+Lj45k/fz7fffcdAOeeey7Tp09n+/btR623RMuWLenevTvTp08HvJBcvnw54N2bGDBgABMmTCApKemYvdlVhwKiErExxoVpycz/Mp89Bwv8LkekUYuJieG1117j7rvvJiMjgz59+rBw4UKKiooYN24caWlp9O3bl9tvv53WrVtz8cUXM2PGjHI3qUv6ewh+vLV79+60atWKxYsXh2zGu6Imv++8806effZZ+vbty7ZtFb83dd1115GVlUVaWhpTpkwpbd67V69e3H///ZxzzjlkZGRwxx13lFt26tSpvPDCC2RkZNCrV6/SG9x33XUXaWlp9O7dm0GDBpGRkRGRn3MwNfd9DFk5O7hi4iKevLoPl/btHPH1i9RVau674VFz3xHWr2sbklsl6jKTiDQ6CohjiIkxLkpL5l9f5bPrgC4ziUjjoYAIw6iMFAqKHHNWb/a7FJFa1VAuQUv1/i0VEGHI6NKK49sepybApVFJTExk+/btCokGwDnH9u3bS9/rCJfegwiDmXFRWgp/+/gbfth3mDbNmvhdkkjUdenShdzcXPLz8/0uRSIgMTGRLl26VGkZBUSYRqUnM/Ff63lv9WauOb2r3+WIRF18fHzpi2TSOOkSU5h6pbSke/tmeppJRBoNBUSYzIxR6cksWr+d/D2H/C5HRCTqFBBVMCo9hWIH763SzWoRafgUEFVwcqcW9OjQnLf0NJOINAIKiCoalZ7C0pwdbNl97JYYRUTqMwVEFY3KSMY5mK2zCBFp4BQQVfSjpOacmtxSTzOJSIOngKiGUenJLPt+J3k7D/hdiohI1CggqmFUutfN4WydRYhIA6aAqIZu7ZqR1rmV7kOISIOmgKimUenJLM/dxffb9/tdiohIVEQ1IMxspJl9aWbrzKxcb+Bm1s3M5prZCjNbYGZdgqYVmdnnga9Z0ayzOi4KXGZ6e6UuM4lIwxS1gDCzWOAZ4AKgJ3CNmfUsM9vjwBTnXDowAfhD0LQDzrk+ga/R0aqzurq0aUrfrq15e7kuM4lIwxTNM4jTgXXOuW+cc4eBl4FLyszTE5gXGJ4fYnqdNio9hTWbdvNN/l6/SxERibhoBkRnYEPQ59zAuGDLgcsDw5cBLcysXeBzopllmdmnZnZpqA2Y2c2BebL8aLP+orRkzFBHQiLSIPl9k/pO4Bwz+ww4B8gDigLTujnnMoFrgSfN7EdlF3bOPeecy3TOZSYlJdVa0SU6tUrktG5t9dKciDRI0QyIPOD4oM9dAuNKOec2Oucud871Be4PjNsZ+J4X+P4NsADoG8Vaq21URjJfbdnLV1v2+F2KiEhERTMglgI9zKy7mTUBxgJHPY1kZu3NrKSGe4FJgfFtzCyhZB7gTGBNFGuttgt6JxNj8PZynUWISMMStYBwzhUCtwLvA2uBV51zq81sgpmVPJU0BPjSzL4COgKPBsafCmSZ2XK8m9ePOefqZEAktUhg4AnteHvFJnXuLiINSlT7pHbOvQO8U2bcg0HDrwGvhVhuIZAWzdoiaVR6CvfNWMmaTbvpldLK73JERCLC75vUDcLI3p2IjTE9zSQiDYoCIgLaNmvCoB+14+0VG3WZSUQaDAVEhFycnsKGHQdYkbvL71JERCJCAREh5/fqRHys6Z0IEWkwFBAR0qppPGf1SGL2ik0UF+syk4jUfwqICBqVnszGXQf5bMNOv0sREakxBUQEDe/ZkSZxMbrMJCINggIiglokxjPkpCTeWanLTCJS/ykgImxURgpbdh9iac4Ov0sREakRBUSEDTulA4nxMXppTkTqPQVEhDVLiGPYKR15d9UmCouK/S5HRKTaFBBRMCo9mW17D7P4W11mEpH6SwERBUNP6UCzJrF6mklE6jUFRBQkxsdyXs+OvLtqMwW6zCQi9ZQCIkouSktm5/4CPlm3ze9SRESqRQERJeecnESLhDg9zSQi9ZYCIkoS4mIZ3qsj76/ezKHCIr/LERGpMgVEFF2cnsKeg4V8/JUuM4lI/aOAiKIzT2xPq+Pi9TSTiNRLCogoahIXw8henfhgzRYOFugyk4jULwqIKBuVkcy+w0Us+HKr36WIiFSJAiLKzjihHe2aNdHTTCJS7yggoiwuNoaRvTsxd+1Wdu0v8LscEZGwKSBqweX9unCwsIjBf5zHI2+t5ttt+/wuSUTkmBQQtaB/tza88fNBDD2lA39f9B1DH1/A+BeXMP/LrepYSETqLHOuYRygMjMzXVZWlt9lHNPW3QeZuvh7/rnke/L3HKJ7+2ZcP7AbV2R2oWVivN/liUgjY2bZzrnMkNMUEP44XFjMu6s2MXlhDp99v5OmTWIZ068LNwzqxokdWvhdnog0EgqIOm5F7k4mL8zh7eWbOFxUzJkntuOGM1IZdmpHYmPM7/JEpAFTQNQT2/Ye4pWlG/jHp9+xaddBurQ5jusHduPq046nddMmfpcnIg1QjQLCzC4GZjvn6nTHBg0hIEoUFhUzZ80WJi/MYcm3O0iMj+HSPp25YVAqpya39Ls8EWlAahoQ/wDOAF4HJjnnvoh8iTXXkAIi2JqNu5myKIc3P8/jYEExp3dvy/hBqYzo2ZG4WD2EJiI1U+NLTGbWErgG+AnggBeBac65PZEstCYaakCU2Ln/MK8s3cCURd+Rt/MAya0SGTewG2NPO552zRP8Lk9E6qmI3IMws3bA9cAvgbXAicDTzrk/R6rQmmjoAVGiqNgxd+0WXlqUwyfrttMkLoaL01MYPyiVtC6t/C5PROqZml5iGo135nAiMAV4yTm31cyaAmucc6kRrrdaGktABPt6yx5eWpTDG8vy2H+4iH5dW3PDoFQu6J1MkzhdfhKRY6tpQLwEvOCc+yjEtGHOubmRKbNmGmNAlNh1oIDXsnP5+6IccrbvJ6lFAtcN6Mq1A7rSoUWi3+WJSB1W04DoDmxyzh0MfD4O6Oicy4l0oTXRmAOiRHGx419f5TN5YQ7/+iqf+FjjwrRkxg3sRrd2TUmIiyUhLoaEuBjM9H6FiNQ8ILKAQc65w4HPTYBPnHOnRbzSGlBAHO2b/L1MWfQdr2XnsvdQYbnpJUGREO+FRmL8kfBIiIslMd77nhAfU2Z60PzxIeaPiwmMLztO4SRSF1UWEHFhLB9XEg4AzrnDgZAIZ8MjgaeAWOBvzrnHykzvBkwCkoAdwDjnXG5g2g3AA4FZf++ceymcbYrnhKTmPDy6F3eefzLzvtjK7gMFHCwo4lBhceCriEMFwd+Lg6YXsX1f4ZHPgfkOFhRzsLCImr5b2SQuhsQyoXFUAMXHkBhXeQCFDKygcCqZFhN0K6YkmKz0c9C0wNiScUdFmB09T6j5gkOv7PqDlytdV4jtlK0v1DpCZWuo7YSz/qP2X6EtIYQTEPlmNto5NwvAzC4Bth1rITOLBZ4BhgO5wFIzm+WcWxM02+PAFOfcS2Z2LvAH4Hozaws8BGTiPVabHVj2h6rsnEDzhDhGZ6REbH3OOQqL3dGBEvh+VACFGhcImeBQOhQUSiXz79tXeFQoBU9T47e1w8pnWlgBFjxDVYO43PorqSHUOioLaY4ZnqHrq2j95ZarZkhXto/H+jkHl3NqckueuLpPufpqKpyAuAWYamZ/wat5A/DjMJY7HVjnnPsGwMxeBi4BggOiJ3BHYHg+8GZg+HzgA+fcjsCyHwAjgWlhbFeiyMyIjzXiY2NonhDOr09kFRSVDZbKg6q45HSn9Js3EHwWVDLoysxz9LgyI0Is5w27iqeVmSdYONs+el3l96NcDWVrD3M7le1jpcuFmq+S/a/qv0Gwyn/Ox95/Qu1HNf8NQuxqufpCr6v8z7ns72mo+oKnu917YMcOOhzaBJ856NuXSDrm/3Dn3HpgoJk1D3zeG+a6O+OFSYlcYECZeZYDl+NdhroMaBF43yLUsp3D3K40YPGxMb6Fk0idsWIF3HorrFsHI0Z4pxPP3AUpKfDUUzCg7KG2esL6X2ZmFwG9gMSS0x/n3IQIbP9O4C9mNh74CMgDisJd2MxuBm4G6Nq1awTKERGp45Yvh+HD4b//G264AeID/cgUFsKrr8KoUTBzJgwaVONNHTMgzGwi0BQYCvwNuAJYEsa684Djgz53CYwr5ZzbiHcGQeAMZYxzbqeZ5QFDyiy7oOwGnHPPAc+B9xRTGDWJiNRvN98Mf/qTFw7B4uLg2muhaVO48UZYuzb0Uw1VEM7rtoOccz8GfnDOPYLXcN9JYSy3FOhhZt0DTz2NBWYFz2Bm7c2spIZ78Z5oAngfGGFmbcysDTAiME5EpPHKzoYtW2DcuIrnueQS76xi3rwaby6cS0wHA9/3m1kKsB1IPtZCzrlCM7sV78Aei9cS7GozmwBkBZ6KGgL8wcwc3iWmXwSW3WFmv8MLGYAJJTesRUTqrOIiKDoMRQWBr8PeV3HhkeGioOHi4PkqWyYwbemncHUHePfOo8e3SYXzHvJqMIPRo+Hf/4Zhw2q0O+EExFtm1hr4E7AM7z778+Gs3Dn3DvBOmXEPBg2/BrxWwbKTOHJGISKNTXHR0QfP4lAH0uDxlU0reyAO9+Bc2frKTC8ugGh2mxMTD8VAgsHaHRDbBGLivO9lLyXFx0NxzWupNCACl3/mOud2Aq+b2dtAonNuV423LCK1p7i4goNbmAe+sP7KLaxg/LEO2hWsL6oH28CBNTbeO/CWDMcGDzfxpsUlQEKLo6fHBM/bBGLjjgzHxIUeX9m2YspsN9S2zGDuXLjjDvj888rvL8yfD7ffXuMfU6UB4ZwrNrNngL6Bz4eAQzXeqkh9Vu5gW4MDaVh/GVdlWxWsz4X9cGDVxcSFOMBVcMCMawKxzSNzwCy3XCUH55gyB+r6+ub40KFw4IAXFOedF3qepUu9x19Hj67x5sK5xDTXzMYAb7iG0oG1NGz7tkHeMti8HA7tidBBO+jAXFy+bauIsdgQB7hKDphNmkXmgFnhwTnEX9Rl541R0/K1JibGe89h3Dh4443yj7J+9hlcfjk88cSRx19rIJyA+Bne286FZnYQ721q55xT58jiv0N7YOPnsHGZFwobl8HO749Mj0us5ABX5oAZ36rmB8wqX4Ios4wOtnIsF1wAzz8PV1wBJ50EF17o/d7MmeNdenrqKbjqqohsKuwe5eo6tebaCBQegs2rjg6D/C8pbZ+gdTfo3A9S+kHn/pCcAQnNfS1ZJGoKCuDNN+HTT712OPr180IjsWp9wNSoNVczOzvU+FAdCIlETHGRd/APDoPNq7xLPADNOnhh0OvyI6HQrJ2/NYvUpvh4uPJK7ytKwrnEdFfQcCJeI3zZwLlRqUgaH+fgh5ygMPjMu2xUsM+bntASUvrAGb84EgatutTfG40i9UQ4jfVdHPzZzI4HnoxaRdLw7dly9JlB3jI4EHgPMjYBktOh77gjYdDuRF2bF/FBdZrEzAVOjXQh0kAd3OWdEQSHwe5Ak1wWA0mnwikXHQmDDj29RyFFxHfh3IP4M0eaK48B+uC9US1ytIIDsHllUBhkw/Z1R6a36Q5dzzgSBsnp3mOaIlInhXMGEfxoUCEwzTn3SZTqkfqiqBDy1x4dBlvXHnlHoHkn70mijLFeGKT0haZt/a1ZRKoknIB4DTjonPcqppnFmllT59z+6JYmdYZzsOOboy8TbVoOhQe86YmtvAA4878Cj5j2g5aR6+ZURPwR1pvUwHlASU9yxwFzgJr3RiF10+6NR4fBxmXevQSAuOO8S0OZPzkSBm1P0BNFIg1QOAGRGNzNqHNur5k1jWJNUpv27wg8VroM8j7zLhXt3exNs1jo2BN6XupdLurcz7upHKvuPkUag3D+p+8zs37OuWUAZtYfOBDdsiQqDu+DTSuOnBnkZcMP3x6Z3u5E6H62FwSd+0OnNIg/zr96RcRX4QTEL4HpZrYRrx2mTsDVUa1KIufQXpg7Ab77BLauOdKEcsvO3n2DftcHmqXoA8e19rdWEalTwnlRbqmZnQKcHBj1pXOuILplSUQ4B2/9F6x+A04YCidf4IVBSj9o0dHv6kSkjgvnPYhfAFOdc6sCn9uY2TXOub9GvTqpmawXYNVrcO5v4ew7/a5GROqZcNovuCnQoxwAzrkfgJuiV5JERF42vHcv9BgBg+/wuxoRqYfCCYhYsyPPMJpZLKC2EOqy/Tvg1fHey2qX/Z/aMRKRagnnJvV7wCtm9n+Bzz8D3o1eSVIjxcUw4xbYswl++r7eXhaRagsnIO4GbgZuCXxegfckk9RFnzwBX78PFz7u3ZAWEammY157cM4VA4uBHLy+IM4F1ka3LKmWbz+Ceb+H3mPgtP/wuxoRqecqPIMws5OAawJf24BXAJxzQ2unNKmS3ZvgtRu9l90ufkpNX4hIjVV2iekL4GNglHNuHYCZ/apWqpKqKSqE13/qvSl9w1uQ0MLvikSkAajsEtPlwCZgvpk9b2bD8N6klrpm3u+8N6Uvfgo6qC8nEYmMCgPCOfemc24scAowH6/JjQ5m9qyZjaitAuUYvngHPnkSMm+E9Kv8rkZEGpBwblLvc879M9A3dRfgM7wnm8RvO76FN2/x2lE6/w9+VyMiDUyV3qByzv3gnHvOOTcsWgVJmAoOwvQbvOGrXoL4RH/rEZEGRw3711fv3eP16nbNy9Am1e9qRKQBUhsM9dHylyH7RRj8K6+FVhGRKFBA1Ddb1sDbv4Jug2HoA35XIyINmAKiPjm0B179sfeewxWT1PWniESVjjD1hXMw6zbYsd57GUAnjiUAAAxqSURBVE4d/ohIlOkMor5Y8jysnuF1/pM62O9qRKQRUEDUB7lZ8P59cNJIOPOXflcjIo2EAqKu278DXr0BWibDpc+q8x8RqTW6B1GXFRfDGzfBvq1wozr/EZHaFdU/R81spJl9aWbrzOyeENO7mtl8M/vMzFaY2YWB8almdsDMPg98TYxmnXXWx/8P1n0IIx+Dzv38rkZEGpmonUEE+q5+BhgO5AJLzWyWc25N0GwPAK865541s57AO0BqYNp651yfaNVX562fD/MfhbSrvIb4RERqWTTPIE4H1jnnvnHOHQZeBi4pM48DWgaGWwEbo1hP/bF7I7z+H5B0Mox6Qp3/iIgvohkQnYENQZ9zA+OCPQyMM7NcvLOH24KmdQ9cevqXmZ0VagNmdrOZZZlZVn5+fgRL91FRAUz/CRQcgKumQEJzvysSkUbK70dirgEmO+e6ABcCfzezGLyOiro65/oCdwD/NLOWZRcOtCyb6ZzLTEpKqtXCo2buI7DhUxj9tHcGISLik2gGRB5wfNDnLoFxwX4KvArgnFsEJALtnXOHnHPbA+OzgfXASVGstW5Y+xYs/DOcdhOkXeF3NSLSyEUzIJYCPcysu5k1AcYCs8rM8z0wDMDMTsULiHwzSwrc5MbMTgB6AN9EsVb/7fgG3vxPSOkH5z/qdzUiItF7isk5V2hmtwLvA7HAJOfcajObAGQ552YBvwaeN7Nf4d2wHu+cc2Z2NjDBzAqAYuAW59yOaNXqu4IDXiN8FuN1/hOX4HdFIiLRfVHOOfcO3s3n4HEPBg2vAc4MsdzrwOvRrK1Oefc3sHklXDsdWnf1uxoREcD/m9Ty2VRYNgXO+jWcNMLvakRESikg/LR5Fcz+NaSeBUPu87saEZGjKCD8cnC3d98hsRWMeUGd/4hInaOjkh+cg1m3wg856vxHROosnUH4YfFEWDMTznsIUsvdoxcRqRMUELVtwxKY8wCcfBEMut3vakREKqSAqE37tsH08dCyM1z6VzXCJyJ1mu5B1JbiokDnP9vgp3PguNZ+VyQiUikFRG356E+wfh5c/BSkNN5uLkSk/tAlptqwYQkseAwyroF+N/hdjYhIWBQQ0eYcvH8/NO8AFz6u+w4iUm8oIKJt7SzIXQJD71PnPyJSryggoqmoAD58GJJOgT7j/K5GRKRKdJM6mrJe9Pp5uPZVNaUhIvWOziCi5eAu+NdjXkN8PdRKq4jUPwqIaPn3k7B/O4z4nW5Mi0i9pICIhl158OlfIe1KSOnrdzUiItWigIiG+Y+CK4Zzf+t3JSIi1aaAiLTNK+Hzf8LpN0Obbn5XIyJSbQqISPvgQa8ToLPv9LsSEZEaUUBE0rq5XntLZ98Fx7XxuxoRkRpRQERKcRF88BC07gqn3+R3NSIiNaa3tyJlxSuwZaXXv3Rcgt/ViIjUmM4gIqHgAMz7vfdIa6/L/a5GRCQidAYRCZ8+C7vz4PLnIEaZKyINg45mNbVvG/z7CTjpAkgd7Hc1IiIRo4CoqX/9DxzeC+c97HclIiIRpYCoie3rIesF6Pdj6HCK39WIiESUAqIm5j4CsQkw5D6/KxERiTgFRHVtWAJrZsKZt0OLjn5XIyIScQqI6nAO5jwAzTvCGbf6XY2ISFQoIKpj7VuwYTEMuVf9TItIg6WAqKqSfqbbnwx9r/e7GhGRqNGLclWVPRl2rIdrXlE/0yLSoOkMoioO7oYFj0G3wXDS+X5XIyISVQqIqvjkSdi/Tf1Mi0ijoIAI1648WPQM9L4COvfzuxoRkahTQIRr/n97/UwPUz/TItI4RDUgzGykmX1pZuvM7J4Q07ua2Xwz+8zMVpjZhUHT7g0s96WZ+XvBf/Mq+HxqoJ/pVF9LERGpLVF7DMfMYoFngOFALrDUzGY559YEzfYA8Kpz7lkz6wm8A6QGhscCvYAU4EMzO8k5VxSteiv1wYOQ2BLO+rUvmxcR8UM0zyBOB9Y5575xzh0GXgYuKTOPA1oGhlsBGwPDlwAvO+cOOee+BdYF1lf71s+D9XO9fqabtvWlBBERP0QzIDoDG4I+5wbGBXsYGGdmuXhnD7dVYVnM7GYzyzKzrPz8/EjVfURxsXf20Lqrd3lJRKQR8fsm9TXAZOdcF+BC4O9mFnZNzrnnnHOZzrnMpKSkyFe34hXYvBLOfVD9TItIoxPNV4HzgOODPncJjAv2U2AkgHNukZklAu3DXDa6SvqZTu4DvcfU6qZFROqCaJ5BLAV6mFl3M2uCd9N5Vpl5vgeGAZjZqUAikB+Yb6yZJZhZd6AHsCSKtZa3eCLszoURv1c/0yLSKEXtDMI5V2hmtwLvA7HAJOfcajObAGQ552YBvwaeN7Nf4d2wHu+cc8BqM3sVWAMUAr+o1SeY9m2Hj/8XThoJ3c+qtc2KiNQl5h2P67/MzEyXlZUVmZW9ezcseQ5+vkhdiYpIg2Zm2c65zFDTdO2krO3rYenfvKa8FQ4i0ogpIMqaO8HrZ3qo+pkWkcZNARFsw1JY8yYMug1adPK7GhERXykgSpT0M92sgxcQIiKNnAKixBdvw4ZPYaj6mRYRAQWE56h+pn/sdzUiInWCOlUGr5/p7evgmpfVz7SISIDOIEr7mT7TezFOREQAnUFAwX7oOhDOukP9TIuIBFFAtOgEY6f6XYWISJ2jS0wiIhKSAkJEREJSQIiISEgKCBERCUkBISIiISkgREQkJAWEiIiEpIAQEZGQGkyXo2aWD3xXg1W0B7ZFqBw/t1EXt+2nxrrf0rjU5Pe8m3MuKdSEBhMQNWVmWRX1y1qftlEXt+2nxrrf0rhE6/dcl5hERCQkBYSIiISkgDjiuQayjbq4bT811v2WxiUqv+e6ByEiIiHpDEJEREJSQIiISEiNPiDMbJKZbTWzVVHcRo6ZrTSzz80sK1rbCWyr3P6YWVsz+8DMvg58bxPNGvxgZseb2XwzW2Nmq83svwLjG/y+S+MT6pgSjd/1Rh8QwGSgNjqjHuqc61MLz+RPpvz+3APMdc71AOYGPjc0hcCvnXM9gYHAL8ysJ41j36VxKntMifjveqMPCOfcR8AOv+uIlAr25xLgpcDwS8CltVpULXDObXLOLQsM7wHWAp1pBPsuEhDx3/VGHxC1xAFzzCzbzG72YfsdnXObAsObgY4+1FBrzCwV6AssppHtuzQaoY4pEf9dj6vpCiQsg51zeWbWAfjAzL4I/KVf65xzzswa7LPNZtYceB34pXNut5mVTmvo+y6NSrljSvDESP2u6wyiFjjn8gLftwIzgNNruYQtZpYMEPi+tZa3XyvMLB4vHKY6594IjG4U+y6NSwXHlIj/risgoszMmplZi5JhYAQQtSemKjALuCEwfAMws5a3H3XmnSq8AKx1zv1v0KQGv+/SuFRyTIn473qjf5PazKYBQ/Cay90CPOSceyGC6z8BL+HBu6T3T+fco5Faf4jtldsf4E3gVaArXpPoVznnGsyNeQAzGwx8DKwEigOj78O7D9Gg910al4qOKWbWjgj/rjf6gBARkdB0iUlEREJSQIiISEgKCBERCUkBISIiISkgREQkJAWESBlm5szsH0Gf48ws38zeDnwebWZVagjNzO4PtDK7ItAC54BjzP+wmd0ZGJ5gZucFhn9pZk2rvlciVaemNkTK2wf0NrPjnHMHgOFAXslE59wsvJeSwmJmZwCjgH7OuUNm1h5oEu7yzrkHgz7+EvgHsD/c5UWqS2cQIqG9A1wUGL4GmFYywczGm9lfAsOTzexpM1toZt+Y2RUh1pUMbHPOHQJwzm1zzm0MLJ9jZv8TaNt/iZmdWHbhwDauMLPbgRRgvpnNj+jeioSggBAJ7WVgrJklAul4b2RXJBkYjHeW8FiI6XOA483sKzP7q5mdU2b6LudcGvAX4MmKNuKcexrYiNcPwNDwd0WkehQQIiE451YAqXhnD+8cY/Y3nXPFzrk1hGhi2Tm3F+gP3AzkA6+Y2figWaYFfT+jZpWLRI7uQYhUbBbwOF7bVu0qme9Q0LCFmsE5VwQsABaY2Uq8xtQml0wOnrV6pYpEns4gRCo2CXjEObeyJisxs5PNrEfQqD54jamVuDro+6JjrG4P0KIm9YiES2cQIhVwzuUCT0dgVc2BP5tZa7y+s9fhXW4q0cbMVuCdiVxzjHU9B7xnZht1H0KiTa25ivjIzHKATOfcNr9rESlLl5hERCQknUGIiEhIOoMQEZGQFBAiIhKSAkJEREJSQIiISEgKCBERCen/A9ieQOno155cAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#from matplotlib import style\n",
        "#style.use('dark_background')\n",
        "plt.plot(min_samples_split,train_accuracies_list, label=\"Train Accuracies\")\n",
        "plt.plot(min_samples_split,test_accuracies_list, label=\"Test Accuracies\")\n",
        "plt.xlabel(\"Min Split\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "best_x_point = min_samples_split[np.argmax(test_accuracies_list)]\n",
        "best_y_point = np.max(test_accuracies_list)\n",
        "_ = plt.scatter([best_x_point],[best_y_point], facecolors='none', edgecolors='r' ,s=100)\n",
        "_ = plt.xticks(min_samples_split)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seOU-9Xpcs_V"
      },
      "source": [
        "Build the best 2 trees:\n",
        "1. tree_max_depth - the best tree according to max_depth pruning\n",
        "1. tree_min_samples_split - the best tree according to min_samples_split pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGQggMxVcs_V"
      },
      "outputs": [],
      "source": [
        "#### Your code here ####\n",
        "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth=4)\n",
        "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmpcyvALcs_W"
      },
      "source": [
        "## Number of Nodes\n",
        "\n",
        "(5 points)\n",
        "\n",
        "Complete the function counts_nodes and print the number of nodes in each tree and print the number of nodes of the two trees above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYUixJSucs_W"
      },
      "outputs": [],
      "source": [
        "def count_nodes(node):\n",
        "    \"\"\"\n",
        "    Count the number of node in a given tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        " \n",
        "    Output: the number of node in the tree.\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    # include node pass in\n",
        "    count = 1\n",
        "    # recurisvely iterate over all children\n",
        "    for child in node.children:\n",
        "      count += count_nodes(child)\n",
        "    return count\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS5LEQs5cs_W"
      },
      "source": [
        "## Print the tree\n",
        "\n",
        "Complete the function `print_tree`. Your tree should be visualized clearly. You can use the following example as a reference:\n",
        "```\n",
        "[ROOT, feature=X0],\n",
        "  [X0=a, feature=X2]\n",
        "    [X2=c, leaf]: [{1.0: 10}]\n",
        "    [X2=d, leaf]: [{0.0: 10}]\n",
        "  [X0=y, feature=X5], \n",
        "    [X5=a, leaf]: [{1.0: 5}]\n",
        "    [X5=s, leaf]: [{0.0: 10}]\n",
        "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
        "```\n",
        "In each brackets:\n",
        "* The first argument is the parent feature with the value that led to current node\n",
        "* The second argument is the selected feature of the current node\n",
        "* If the current node is a leaf, you need to print also the labels and their counts\n",
        "\n",
        "(5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5GfEMTHcs_W"
      },
      "outputs": [],
      "source": [
        "# you can change the function signeture\n",
        "def print_tree(node, depth=0, parent_feature='ROOT', feature_val='ROOT'):\n",
        "    '''\n",
        "    prints the tree according to the example above\n",
        "\n",
        "    Input:\n",
        "    - node: a node in the decision tree\n",
        "\n",
        "    This function has no return value\n",
        "    '''\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    #print root\n",
        "    if parent_feature=='ROOT':\n",
        "        print('  '*depth,f'[ROOT, feature={allFeatures[node.feature]}]')\n",
        "    #printing non leaf \n",
        "    elif (len(node.children) >= 1):\n",
        "        print('  '*depth,f'[{allFeatures[parent_feature]}={feature_val}, feature={allFeatures[node.feature]}]')\n",
        "    #printing leafs\n",
        "    else:\n",
        "        classes, number_of_instances = np.unique(node.data.to_numpy()[:,-1], return_counts=True)\n",
        "        if classes.size < 2:\n",
        "            print('  '*depth,f'[{allFeatures[parent_feature]}={feature_val},leaf]:[{{{classes[0]}:{number_of_instances[0]}}}]')\n",
        "        else:\n",
        "            print('  '*depth,f'[{allFeatures[parent_feature]}={feature_val},leaf]:[{{{classes[0]}:{number_of_instances[0]}, {classes[1]}:{number_of_instances[1]}}}]')\n",
        "    #print children\n",
        "    for child in node.children:\n",
        "        print_tree(child, child.depth, node.feature, child.feature_value)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDsxdze_cs_X"
      },
      "source": [
        "print the tree with the best test accuracy and with less than 50 nodes (from the two pruning methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s2dKLo6cs_X",
        "outputId": "9cac3e4d-ff27-46e6-ec29-a800827fbcd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [ROOT, feature=odor]\n",
            "   [odor=a,leaf]:[{e:273, p:31}]\n",
            "   [odor=c,leaf]:[{e:10, p:137}]\n",
            "   [odor=f,leaf]:[{e:170, p:1438}]\n",
            "   [odor=l,leaf]:[{e:272, p:27}]\n",
            "   [odor=m,leaf]:[{e:2, p:25}]\n",
            "   [odor=n,leaf]:[{e:2332, p:344}]\n",
            "   [odor=p,leaf]:[{e:8, p:175}]\n",
            "   [odor=s,leaf]:[{e:38, p:380}]\n",
            "   [odor=y,leaf]:[{e:49, p:382}]\n"
          ]
        }
      ],
      "source": [
        "#### Your code here ####\n",
        "allFeatures = list(data.columns)\n",
        "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth=1)\n",
        "print_tree(tree_entropy_gain_ratio)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "collapsed_sections": [],
      "name": "hw2_303012561_345428312.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
